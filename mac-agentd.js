#!/usr/bin/env node
// mac-agentd v1.0 — OpenClaw Host Execution Service
// Structured HTTP daemon replacing `claude -p` with capability-based endpoints
// Binds 127.0.0.1:7777 — loopback only, no external access

"use strict";

const http = require("http");
const fs = require("fs");
const path = require("path");
const crypto = require("crypto");
const { execFile, spawn } = require("child_process");

// ─── Configuration ───────────────────────────────────────────────

const PORT = 7777;
const HOST = "127.0.0.1";
const TOKEN_PATH = path.join(process.env.HOME || "/Users/rexmacmini", ".agentd-token");
const AUDIT_LOG_PATH = path.join(process.env.HOME || "/Users/rexmacmini", ".agentd-audit.jsonl");
const AUDIT_MAX_SIZE = 10 * 1024 * 1024; // 10MB
const HEARTBEAT_PATH = "/tmp/mac-agentd.alive";
const JOBS_DIR = "/tmp/mac-agentd/jobs";
const MAX_OUTPUT = 100 * 1024; // 100KB
const RATE_WINDOW_MS = 5 * 60 * 1000; // 5 min
const RATE_MAX = 100;

// Path sandbox — only these prefixes allowed
const ALLOWED_PATHS = [
  "/Users/rexmacmini/openclaw",
  "/Users/rexmacmini/Project/active_projects",
  "/tmp/mac-agentd",
];

// Container whitelist
// v10.3: Updated to match all running containers
const ALLOWED_CONTAINERS = new Set([
  "openclaw-agent",
  "postgres",
  "redis",
  "backend",
  "grafana",
  "prometheus",
  "personal-ai-gateway",
  "rex-ai",
  "taiwan-stock-backend",
  "taiwan-stock-grafana",
  "taiwan-stock-prometheus",
  "taiwan-stock-postgres",
  "taiwan-stock-redis",
]);

// ─── Token Loading ───────────────────────────────────────────────

let AUTH_TOKEN = null;

function loadToken() {
  try {
    AUTH_TOKEN = fs.readFileSync(TOKEN_PATH, "utf8").trim();
    if (AUTH_TOKEN.length < 32) {
      console.error("[agentd] FATAL: token too short (min 32 chars)");
      process.exit(1);
    }
    console.log(`[agentd] Token loaded (${AUTH_TOKEN.length} chars)`);
  } catch (e) {
    console.error(`[agentd] FATAL: cannot read token: ${e.message}`);
    process.exit(1);
  }
}

// ─── Security Helpers ────────────────────────────────────────────

function verifyToken(req) {
  const auth = req.headers["authorization"] || "";
  const match = auth.match(/^Bearer\s+(.+)$/);
  if (!match) {
    return false;
  }
  const provided = Buffer.from(match[1]);
  const expected = Buffer.from(AUTH_TOKEN);
  if (provided.length !== expected.length) {
    return false;
  }
  return crypto.timingSafeEqual(provided, expected);
}

function isAllowedPath(p) {
  const resolved = path.resolve(p);
  return ALLOWED_PATHS.some((prefix) => resolved.startsWith(prefix));
}

function isAllowedContainer(name) {
  return ALLOWED_CONTAINERS.has(name);
}

// Strict schema validation — reject extra fields + type check
function validateSchema(body, schema) {
  if (typeof body !== "object" || body === null || Array.isArray(body)) {
    return "body must be a JSON object";
  }
  const bodyKeys = Object.keys(body);
  const schemaKeys = Object.keys(schema);
  // Check for extra fields
  for (const key of bodyKeys) {
    if (!schema.hasOwnProperty(key)) {
      return `unexpected field: ${key}`;
    }
  }
  // Check required fields and types
  for (const [key, spec] of Object.entries(schema)) {
    if (spec.required && body[key] === undefined) {
      return `missing required field: ${key}`;
    }
    if (body[key] !== undefined) {
      if (spec.type === "string" && typeof body[key] !== "string") {
        return `${key} must be a string`;
      }
      if (spec.type === "number" && typeof body[key] !== "number") {
        return `${key} must be a number`;
      }
      if (spec.type === "boolean" && typeof body[key] !== "boolean") {
        return `${key} must be a boolean`;
      }
      if (
        spec.type === "string[]" &&
        (!Array.isArray(body[key]) || !body[key].every((x) => typeof x === "string"))
      ) {
        return `${key} must be an array of strings`;
      }
    }
  }
  return null;
}

// ─── Rate Limiting ───────────────────────────────────────────────

const rateHits = [];

function checkRateLimit() {
  const now = Date.now();
  while (rateHits.length > 0 && now - rateHits[0] > RATE_WINDOW_MS) {
    rateHits.shift();
  }
  if (rateHits.length >= RATE_MAX) {
    return false;
  }
  rateHits.push(now);
  return true;
}

// ─── Serial Execution Queue ─────────────────────────────────────

let queueBusy = false;
const queue = [];

function enqueue(fn) {
  return new Promise((resolve, reject) => {
    queue.push({ fn, resolve, reject });
    void processQueue();
  });
}

async function processQueue() {
  if (queueBusy || queue.length === 0) {
    return;
  }
  queueBusy = true;
  const { fn, resolve, reject } = queue.shift();
  try {
    const result = await fn();
    resolve(result);
  } catch (e) {
    reject(e);
  } finally {
    queueBusy = false;
    if (queue.length > 0) {
      void processQueue();
    }
  }
}

// ─── Job Model ───────────────────────────────────────────────────

function createJobId() {
  return `j-${Date.now()}-${crypto.randomBytes(4).toString("hex")}`;
}

// ─── Audit Logging ───────────────────────────────────────────────

function auditLog(entry) {
  const record = JSON.stringify({ ts: new Date().toISOString(), ...entry }) + "\n";
  fs.appendFile(AUDIT_LOG_PATH, record, (err) => {
    if (err) {
      console.error(`[agentd] audit write error: ${err.message}`);
    }
  });
  // Rotation check
  try {
    const stat = fs.statSync(AUDIT_LOG_PATH);
    if (stat.size > AUDIT_MAX_SIZE) {
      const rotated = AUDIT_LOG_PATH + "." + Date.now();
      fs.renameSync(AUDIT_LOG_PATH, rotated);
      console.log(`[agentd] audit log rotated → ${rotated}`);
    }
  } catch (_) {}
}

// ─── Shell Execution Helper ──────────────────────────────────────

function execCommand(cmd, args, opts = {}) {
  return new Promise((resolve, reject) => {
    const child = execFile(
      cmd,
      args,
      {
        timeout: opts.timeout || 30000,
        maxBuffer: MAX_OUTPUT,
        env: { ...process.env, PATH: "/opt/homebrew/bin:/usr/local/bin:/usr/bin:/bin" },
        cwd: opts.cwd,
        shell: false,
      },
      (err, stdout, stderr) => {
        if (err && !stdout) {
          reject(new Error(stderr ? stderr.slice(0, 2000) : err.message));
        } else {
          resolve({
            stdout: stdout.slice(0, MAX_OUTPUT),
            stderr: stderr.slice(0, 2000),
            code: err ? err.code : 0,
          });
        }
      },
    );
  });
}

// ─── Heartbeat ───────────────────────────────────────────────────

function writeHeartbeat() {
  fs.writeFile(HEARTBEAT_PATH, new Date().toISOString(), () => {});
}

// ─── Route Handlers ──────────────────────────────────────────────

const routes = {};

// GET /health
routes["GET /health"] = async () => {
  return { status: "ok", uptime: process.uptime(), queue: queue.length, busy: queueBusy };
};

// GET /audit-log
routes["GET /audit-log"] = async (body, url) => {
  const params = new URL(url, "http://localhost").searchParams;
  const limit = Math.min(parseInt(params.get("limit") || "50", 10), 200);
  try {
    const data = fs.readFileSync(AUDIT_LOG_PATH, "utf8");
    const lines = data.trim().split("\n").slice(-limit);
    return lines.map((l) => {
      try {
        return JSON.parse(l);
      } catch {
        return l;
      }
    });
  } catch {
    return [];
  }
};

// POST /fs/read
routes["POST /fs/read"] = async (body) => {
  const err = validateSchema(body, {
    path: { type: "string", required: true },
    offset: { type: "number" },
    limit: { type: "number" },
  });
  if (err) {
    throw { status: 400, message: err };
  }
  if (!isAllowedPath(body.path)) {
    throw { status: 403, message: "path not allowed" };
  }

  const content = fs.readFileSync(body.path, "utf8");
  const lines = content.split("\n");
  const offset = body.offset || 0;
  const limit = body.limit || lines.length;
  return {
    path: body.path,
    lines: lines.length,
    content: lines.slice(offset, offset + limit).join("\n"),
  };
};

// POST /fs/write
routes["POST /fs/write"] = async (body) => {
  const err = validateSchema(body, {
    path: { type: "string", required: true },
    content: { type: "string", required: true },
    mode: { type: "string" },
  });
  if (err) {
    throw { status: 400, message: err };
  }
  if (!isAllowedPath(body.path)) {
    throw { status: 403, message: "path not allowed" };
  }

  const dir = path.dirname(body.path);
  if (!fs.existsSync(dir)) {
    fs.mkdirSync(dir, { recursive: true });
  }
  fs.writeFileSync(body.path, body.content, { mode: body.mode ? parseInt(body.mode, 8) : 0o644 });
  return { path: body.path, bytes: Buffer.byteLength(body.content), ok: true };
};

// POST /fs/list
routes["POST /fs/list"] = async (body) => {
  const err = validateSchema(body, {
    path: { type: "string", required: true },
  });
  if (err) {
    throw { status: 400, message: err };
  }
  if (!isAllowedPath(body.path)) {
    throw { status: 403, message: "path not allowed" };
  }

  const entries = fs.readdirSync(body.path, { withFileTypes: true });
  return {
    path: body.path,
    entries: entries.map((e) => ({ name: e.name, type: e.isDirectory() ? "dir" : "file" })),
  };
};

// POST /git/log
routes["POST /git/log"] = async (body) => {
  const err = validateSchema(body, {
    repo: { type: "string", required: true },
    count: { type: "number" },
  });
  if (err) {
    throw { status: 400, message: err };
  }
  if (!isAllowedPath(body.repo)) {
    throw { status: 403, message: "repo not allowed" };
  }

  const count = Math.min(body.count || 10, 50);
  const result = await execCommand("git", ["log", `--oneline`, `-${count}`], { cwd: body.repo });
  return { repo: body.repo, log: result.stdout };
};

// POST /git/status
routes["POST /git/status"] = async (body) => {
  const err = validateSchema(body, {
    repo: { type: "string", required: true },
  });
  if (err) {
    throw { status: 400, message: err };
  }
  if (!isAllowedPath(body.repo)) {
    throw { status: 403, message: "repo not allowed" };
  }

  const result = await execCommand("git", ["status", "--short"], { cwd: body.repo });
  return { repo: body.repo, status: result.stdout };
};

// POST /git/diff
routes["POST /git/diff"] = async (body) => {
  const err = validateSchema(body, {
    repo: { type: "string", required: true },
    cached: { type: "boolean" },
  });
  if (err) {
    throw { status: 400, message: err };
  }
  if (!isAllowedPath(body.repo)) {
    throw { status: 403, message: "repo not allowed" };
  }

  const args = ["diff"];
  if (body.cached) {
    args.push("--cached");
  }
  const result = await execCommand("git", args, { cwd: body.repo });
  return { repo: body.repo, diff: result.stdout };
};

// POST /git/add
routes["POST /git/add"] = async (body) => {
  const err = validateSchema(body, {
    repo: { type: "string", required: true },
    files: { type: "string[]", required: true },
  });
  if (err) {
    throw { status: 400, message: err };
  }
  if (!isAllowedPath(body.repo)) {
    throw { status: 403, message: "repo not allowed" };
  }
  if (body.files.length === 0) {
    throw { status: 400, message: "files array cannot be empty" };
  }
  if (body.files.length > 20) {
    throw { status: 400, message: "too many files (max 20)" };
  }
  // Reject path traversal in file names (allow -u flag for tracked files)
  const gitAddArgs = ["add"];
  const hasUpdateFlag = body.files.length === 1 && body.files[0] === "-u";
  if (hasUpdateFlag) {
    gitAddArgs.push("-u");
  } else {
    for (const f of body.files) {
      if (f.includes("..") || f.startsWith("/")) {
        throw { status: 400, message: `invalid file path: ${f}` };
      }
    }
    gitAddArgs.push("--", ...body.files);
  }

  const result = await execCommand("git", gitAddArgs, { cwd: body.repo });
  return { repo: body.repo, added: body.files, ok: true };
};

// POST /git/commit
routes["POST /git/commit"] = async (body) => {
  const err = validateSchema(body, {
    repo: { type: "string", required: true },
    message: { type: "string", required: true },
  });
  if (err) {
    throw { status: 400, message: err };
  }
  if (!isAllowedPath(body.repo)) {
    throw { status: 403, message: "repo not allowed" };
  }
  if (body.message.length < 3) {
    throw { status: 400, message: "commit message too short" };
  }
  if (body.message.length > 500) {
    throw { status: 400, message: "commit message too long (max 500)" };
  }

  const result = await execCommand("git", ["commit", "-m", body.message], { cwd: body.repo });
  return { repo: body.repo, output: result.stdout, ok: true };
};

// POST /docker/ps
routes["POST /docker/ps"] = async (body) => {
  const err = validateSchema(body, {});
  if (err) {
    throw { status: 400, message: err };
  }

  const result = await execCommand("docker", [
    "ps",
    "--format",
    "{{.Names}}\t{{.Status}}\t{{.Image}}",
  ]);
  return { containers: result.stdout };
};

// POST /docker/restart
routes["POST /docker/restart"] = async (body) => {
  const err = validateSchema(body, {
    container: { type: "string", required: true },
  });
  if (err) {
    throw { status: 400, message: err };
  }
  if (!isAllowedContainer(body.container)) {
    throw { status: 403, message: `container not in whitelist: ${body.container}` };
  }

  const result = await execCommand("docker", ["restart", body.container], { timeout: 60000 });
  return { container: body.container, output: result.stdout, ok: true };
};

// POST /docker/logs
routes["POST /docker/logs"] = async (body) => {
  const err = validateSchema(body, {
    container: { type: "string", required: true },
    tail: { type: "number" },
  });
  if (err) {
    throw { status: 400, message: err };
  }
  if (!isAllowedContainer(body.container)) {
    throw { status: 403, message: `container not in whitelist: ${body.container}` };
  }

  const tail = Math.min(body.tail || 50, 200);
  const result = await execCommand("docker", ["logs", "--tail", String(tail), body.container]);
  // docker logs outputs to stderr
  return { container: body.container, logs: result.stdout || result.stderr };
};

// POST /project/test
routes["POST /project/test"] = async (body) => {
  const err = validateSchema(body, {
    repo: { type: "string", required: true },
  });
  if (err) {
    throw { status: 400, message: err };
  }
  if (!isAllowedPath(body.repo)) {
    throw { status: 403, message: "repo not allowed" };
  }

  const jobId = createJobId();
  const logPath = path.join(JOBS_DIR, `${jobId}.log`);

  // Detect test runner
  let cmd, args;
  const resolved = path.resolve(body.repo);
  if (
    fs.existsSync(path.join(resolved, "pytest.ini")) ||
    fs.existsSync(path.join(resolved, "pyproject.toml"))
  ) {
    cmd = "python3";
    args = ["-m", "pytest", "--tb=short", "-q"];
  } else if (fs.existsSync(path.join(resolved, "package.json"))) {
    cmd = "npm";
    args = ["test"];
  } else {
    throw {
      status: 400,
      message: "no test runner detected (need pytest.ini/pyproject.toml or package.json)",
    };
  }

  try {
    const result = await execCommand(cmd, args, { cwd: resolved, timeout: 120000 });
    const output = result.stdout + (result.stderr ? "\n" + result.stderr : "");
    if (output.length > MAX_OUTPUT) {
      fs.writeFileSync(logPath, output);
      return {
        job_id: jobId,
        summary: output.slice(0, 2000) + "\n... (full output in artifact)",
        artifact: logPath,
      };
    }
    return { job_id: jobId, output, ok: true };
  } catch (e) {
    return { job_id: jobId, error: e.message, ok: false };
  }
};

// GET /system/info
routes["GET /system/info"] = async () => {
  const nodeVersion = process.version;
  const platform = process.platform;
  const arch = process.arch;
  const hostname = require("os").hostname();
  const uptime = require("os").uptime();

  // Get Claude Code version
  let claudeVersion = "unknown";
  try {
    const { execFileSync } = require("child_process");
    claudeVersion = execFileSync("/opt/homebrew/bin/claude", ["--version"], {
      timeout: 5000,
      env: { ...process.env, PATH: "/opt/homebrew/bin:/usr/local/bin:/usr/bin:/bin" },
    })
      .toString()
      .trim();
  } catch (e) {
    claudeVersion = "not installed or error: " + e.message;
  }

  // Get Ollama models
  let ollamaModels = "unknown";
  try {
    const { execFileSync } = require("child_process");
    ollamaModels = execFileSync("curl", ["-s", "http://127.0.0.1:11434/api/tags"], {
      timeout: 3000,
    })
      .toString()
      .trim();
    const parsed = JSON.parse(ollamaModels);
    ollamaModels = (parsed.models || [])
      .map((m) => m.name + " (" + (m.size / 1e9).toFixed(1) + "GB)")
      .join(", ");
  } catch (e) {
    ollamaModels = "error: " + e.message;
  }

  // Get Docker info
  let dockerContainers = "unknown";
  try {
    const { execFileSync } = require("child_process");
    dockerContainers = execFileSync(
      "/usr/local/bin/docker",
      ["ps", "--format", "{{.Names}}: {{.Status}}"],
      {
        timeout: 5000,
      },
    )
      .toString()
      .trim();
  } catch (e) {
    dockerContainers = "error: " + e.message;
  }

  return {
    hostname,
    platform,
    arch,
    node_version: nodeVersion,
    claude_code_version: claudeVersion,
    ollama_models: ollamaModels,
    docker_containers: dockerContainers,
    system_uptime_hours: Math.round(uptime / 3600),
    agentd_uptime_seconds: Math.round(process.uptime()),
  };
};

// ─── HTTP Server ─────────────────────────────────────────────────

function parseBody(req) {
  return new Promise((resolve, reject) => {
    let data = "";
    req.on("data", (chunk) => {
      data += chunk;
      if (data.length > 1024 * 1024) {
        // 1MB max body
        reject(new Error("body too large"));
        req.destroy();
      }
    });
    req.on("end", () => {
      if (!data) {
        return resolve({});
      }
      try {
        resolve(JSON.parse(data));
      } catch {
        reject(new Error("invalid JSON"));
      }
    });
    req.on("error", reject);
  });
}

function sendJSON(res, status, data) {
  const body = JSON.stringify(data);
  res.writeHead(status, {
    "Content-Type": "application/json",
    "Content-Length": Buffer.byteLength(body),
  });
  res.end(body);
}

const server = http.createServer(async (req, res) => {
  const startTime = Date.now();
  const url = req.url.split("?")[0];
  const method = req.method;
  const routeKey = `${method} ${url}`;

  // Auth check (except nothing — all endpoints require auth)
  if (!verifyToken(req)) {
    sendJSON(res, 401, { error: "unauthorized" });
    return;
  }

  // Rate limit
  if (!checkRateLimit()) {
    sendJSON(res, 429, { error: "rate limit exceeded (100 req / 5 min)" });
    return;
  }

  const handler = routes[routeKey];
  if (!handler) {
    sendJSON(res, 404, { error: `unknown endpoint: ${routeKey}` });
    return;
  }

  const jobId = createJobId();
  let body = {};

  try {
    if (method === "POST") {
      body = await parseBody(req);
    }

    // Determine risk level
    const risk = url.includes("/docker/restart")
      ? "destructive"
      : url.includes("/fs/write") || url.includes("/git/commit") || url.includes("/git/add")
        ? "write"
        : url.includes("/project/test")
          ? "exec"
          : "read";

    // Execute through serial queue for write/destructive/exec ops
    let result;
    if (risk === "read") {
      result = await handler(body, req.url);
    } else {
      result = await enqueue(() => handler(body, req.url));
    }

    const elapsed = Date.now() - startTime;
    auditLog({
      job_id: jobId,
      capability: url,
      risk,
      params: body,
      elapsed_ms: elapsed,
      success: true,
    });
    console.log(`[agentd] ${routeKey} → 200 (${elapsed}ms) [${jobId}]`);
    sendJSON(res, 200, { job_id: jobId, ...result });
  } catch (e) {
    const elapsed = Date.now() - startTime;
    const status = e.status || 500;
    const message = e.message || "internal error";
    auditLog({
      job_id: jobId,
      capability: url,
      params: body,
      elapsed_ms: elapsed,
      success: false,
      error: message,
    });
    console.error(`[agentd] ${routeKey} → ${status} (${elapsed}ms) [${jobId}]: ${message}`);
    sendJSON(res, status, { error: message });
  }
});

// ─── Start ───────────────────────────────────────────────────────

loadToken();

// Ensure jobs dir
if (!fs.existsSync(JOBS_DIR)) {
  fs.mkdirSync(JOBS_DIR, { recursive: true });
}

// Heartbeat interval
setInterval(writeHeartbeat, 10000);
writeHeartbeat();

server.listen(PORT, HOST, () => {
  console.log(`[agentd] mac-agentd v1.0 listening on ${HOST}:${PORT}`);
  console.log(`[agentd] Allowed paths: ${ALLOWED_PATHS.join(", ")}`);
  console.log(`[agentd] Allowed containers: ${[...ALLOWED_CONTAINERS].join(", ")}`);
  console.log(`[agentd] Serial queue: concurrency 1`);
  console.log(`[agentd] Rate limit: ${RATE_MAX} req / ${RATE_WINDOW_MS / 60000} min`);
  console.log(`[agentd] Audit log: ${AUDIT_LOG_PATH} (max ${AUDIT_MAX_SIZE / 1024 / 1024}MB)`);
  console.log(`[agentd] Heartbeat: ${HEARTBEAT_PATH} (10s interval)`);
});

server.on("error", (err) => {
  console.error(`[agentd] FATAL: ${err.message}`);
  process.exit(1);
});

process.on("SIGTERM", () => {
  console.log("[agentd] Received SIGTERM, shutting down...");
  server.close(() => process.exit(0));
});

process.on("SIGINT", () => {
  console.log("[agentd] Received SIGINT, shutting down...");
  server.close(() => process.exit(0));
});

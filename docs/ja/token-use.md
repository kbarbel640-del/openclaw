---
summary: "OpenClaw がプロンプトコンテキストを構築し、トークン使用量 + コストをレポートする方法"
read_when:
  - トークン使用量、コスト、またはコンテキストウィンドウを説明する場合
  - コンテキストの増加やコンパクション挙動をデバッグする場合
title: "トークン使用量とコスト"
x-i18n:
  source_path: token-use.md
  source_hash: cc914080a809ada2
  provider: openai
  model: gpt-5.2-pro
  workflow: v1
  generated_at: 2026-02-06T05:11:35Z
---

# トークン使用量 & コスト

OpenClaw は文字数ではなく **トークン** を追跡します。トークンはモデル固有ですが、ほとんどの OpenAI 風モデルでは、英語テキストは 1 トークンあたり平均約 4 文字です。

## システムプロンプトの構築方法

OpenClaw は実行のたびに独自のシステムプロンプトを組み立てます。含まれるものは次のとおりです。

- ツール一覧 + 短い説明
- Skills 一覧（メタデータのみ。指示は `read` でオンデマンドに読み込まれます）
- セルフアップデート手順
- ワークスペース + ブートストラップファイル（新規の場合は `AGENTS.md`、`SOUL.md`、`TOOLS.md`、`IDENTITY.md`、`USER.md`、`HEARTBEAT.md`、`BOOTSTRAP.md`）。大きいファイルは `agents.defaults.bootstrapMaxChars` により切り詰められます（デフォルト: 20000）。
- 時刻（UTC + ユーザーのタイムゾーン）
- 返信タグ + ハートビート挙動
- ランタイムメタデータ（ホスト/OS/モデル/思考）

完全な内訳は [System Prompt](/concepts/system-prompt) を参照してください。

## コンテキストウィンドウにカウントされるもの

モデルが受け取るすべてのものが、コンテキスト上限に対してカウントされます。

- システムプロンプト（上記に列挙したすべてのセクション）
- 会話履歴（ユーザー + アシスタントメッセージ）
- ツール呼び出しとツール結果
- 添付/トランスクリプト（画像、音声、ファイル）
- コンパクション要約とプルーニング成果物
- プロバイダーのラッパーや安全性ヘッダー（見えませんが、カウントされます）

実用的な内訳（注入されたファイルごと、ツール、Skills、システムプロンプトサイズごと）を確認するには、`/context list` または `/context detail` を使用してください。[Context](/concepts/context) も参照してください。

## 現在のトークン使用量の確認方法

チャットでは次を使用します。

- `/status` → セッションモデル、コンテキスト使用量、直近レスポンスの入力/出力トークン、**推定コスト**（API キーのみ）を含む **絵文字多めのステータスカード**。
- `/usage off|tokens|full` → すべての返信に **レスポンスごとの使用量フッター** を追加します。
  - セッションごとに永続化されます（`responseUsage` として保存）。
  - OAuth 認証では **コストは非表示**（トークンのみ）。
- `/usage cost` → OpenClaw のセッションログからローカルのコスト概要を表示します。

その他の表示面:

- **TUI/Web TUI:** `/status` + `/usage` がサポートされています。
- **CLI:** `openclaw status --usage` と `openclaw channels list` は、プロバイダーのクォータウィンドウ（レスポンスごとのコストではありません）を表示します。

## コスト見積もり（表示される場合）

コストは、モデルの価格設定 config から推定されます。

```
models.providers.<provider>.models[].cost
```

これらは `input`、`output`、`cacheRead`、および
`cacheWrite` に対する **100 万トークンあたりの USD** です。価格設定が欠けている場合、OpenClaw はトークンのみを表示します。OAuth トークンでは、ドル建てコストは決して表示されません。

## キャッシュ TTL とプルーニングの影響

プロバイダーのプロンプトキャッシュは、キャッシュ TTL ウィンドウ内でのみ適用されます。OpenClaw は任意で **cache-ttl プルーニング** を実行できます。キャッシュ TTL が期限切れになったらセッションをプルーニングし、その後キャッシュウィンドウをリセットします。これにより、以降のリクエストでは履歴全体を再キャッシュする代わりに、キャッシュされたばかりの新鮮なコンテキストを再利用できます。これにより、セッションが TTL を超えてアイドル状態になった場合のキャッシュ書き込みコストを低く抑えられます。

設定は [Gateway configuration](/gateway/configuration) で行い、挙動の詳細は [Session pruning](/concepts/session-pruning) を参照してください。

ハートビートにより、アイドルの隙間をまたいでもキャッシュを **ウォーム** に保てます。モデルのキャッシュ TTL が `1h` の場合、ハートビート間隔をそれより少し短く（例: `55m`）設定すると、プロンプト全体の再キャッシュを回避でき、キャッシュ書き込みコストを削減できます。

Anthropic API の価格設定では、キャッシュ読み取りは入力トークンより大幅に安い一方で、キャッシュ書き込みはより高い倍率で課金されます。最新のレートと TTL 倍率については、Anthropic のプロンプトキャッシュ価格設定を参照してください。
https://docs.anthropic.com/docs/build-with-claude/prompt-caching

### 例: ハートビートで 1h キャッシュをウォームに保つ

```yaml
agents:
  defaults:
    model:
      primary: "anthropic/claude-opus-4-6"
    models:
      "anthropic/claude-opus-4-6":
        params:
          cacheRetention: "long"
    heartbeat:
      every: "55m"
```

## トークン圧迫を減らすためのヒント

- `/compact` を使って長いセッションを要約します。
- ワークフロー内の大きなツール出力をトリミングします。
- スキル説明は短く保ちます（Skills 一覧はプロンプトに注入されます）。
- 冗長で探索的な作業には、より小さいモデルを優先します。

スキル一覧の正確なオーバーヘッド計算式については、[Skills](/tools/skills) を参照してください。

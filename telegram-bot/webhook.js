const { Bot, InlineKeyboard, webhookCallback } = require("grammy");

const bot = new Bot(process.env.TELEGRAM_BOT_TOKEN || "");

const MODELS = {
  "llama-3.3-70b-versatile": "ðŸ¦™ Llama 3.3 70B",
  "llama-3.1-8b-instant": "âš¡ Llama 3.1 8B",
  "mixtral-8x7b-32768": "ðŸ”€ Mixtral 8x7B"
};

const userModels = new Map();

const mainMenu = () => new InlineKeyboard()
  .text("ðŸ¤– ÐœÐ¾Ð´ÐµÐ»ÑŒ", "models")
  .text("ðŸ” ÐŸÐ¾Ð¸ÑÐº", "search").row()
  .text("ðŸ“° ÐÐ¾Ð²Ð¾ÑÑ‚Ð¸", "news")
  .text("â“ ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒ", "help");

const modelsMenu = () => {
  const kb = new InlineKeyboard();
  for (const [id, name] of Object.entries(MODELS)) {
    kb.text(name, `set_${id}`).row();
  }
  kb.text("Â« ÐÐ°Ð·Ð°Ð´", "menu");
  return kb;
};

bot.api.setMyCommands([
  { command: "start", description: "ðŸ  Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ" },
  { command: "help", description: "â“ ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒ" }
]).catch(() => {});

bot.command("start", async (ctx) => {
  await ctx.reply("ðŸ¦ž *OpenClaw AI Bot*\n\nÐ’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ:", 
    { reply_markup: mainMenu(), parse_mode: "Markdown" });
});

bot.command("help", async (ctx) => {
  await ctx.reply("ðŸ“– *ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒ*\n\nâ€¢ /start - Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ\nâ€¢ Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»ÑŒ AI\nâ€¢ ÐŸÐ¸ÑˆÐ¸Ñ‚Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ - Ñ Ð¾Ñ‚Ð²ÐµÑ‡Ñƒ!", 
    { parse_mode: "Markdown" });
});

bot.on("callback_query:data", async (ctx) => {
  const data = ctx.callbackQuery.data;
  const userId = ctx.from.id;
  await ctx.answerCallbackQuery();
  
  if (data.startsWith("set_")) {
    const model = data.replace("set_", "");
    userModels.set(userId, model);
    await ctx.editMessageText(`âœ… Ð’Ñ‹Ð±Ñ€Ð°Ð½Ð°: ${MODELS[model]}`, 
      { reply_markup: new InlineKeyboard().text("Â« ÐœÐµÐ½ÑŽ", "menu"), parse_mode: "Markdown" });
    return;
  }
  
  switch (data) {
    case "menu":
      await ctx.editMessageText("ðŸ¦ž *OpenClaw AI Bot*\n\nÐ’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ:", 
        { reply_markup: mainMenu(), parse_mode: "Markdown" });
      break;
    case "models":
      await ctx.editMessageText("ðŸ¤– *Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»ÑŒ:*", 
        { reply_markup: modelsMenu(), parse_mode: "Markdown" });
      break;
    case "search":
      await ctx.editMessageText("ðŸ” Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð²Ð°Ñˆ Ð·Ð°Ð¿Ñ€Ð¾Ñ:");
      break;
    case "news":
      await ctx.editMessageText("ðŸ“° Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸...");
      try {
        const model = userModels.get(userId) || "llama-3.1-8b-instant";
        const response = await askGroq(model, "ÐšÑ€Ð°Ñ‚ÐºÐ¾ Ñ€Ð°ÑÑÐºÐ°Ð¶Ð¸ Ð³Ð»Ð°Ð²Ð½Ñ‹Ðµ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ Ð² Ð¼Ð¸Ñ€Ðµ Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ð¹ ÑÐµÐ³Ð¾Ð´Ð½Ñ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼");
        await ctx.editMessageText(`ðŸ“° *ÐÐ¾Ð²Ð¾ÑÑ‚Ð¸:*\n\n${response}`, 
          { reply_markup: new InlineKeyboard().text("Â« ÐœÐµÐ½ÑŽ", "menu"), parse_mode: "Markdown" });
      } catch (e) {
        await ctx.editMessageText(`âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: ${e.message}`);
      }
      break;
    case "help":
      await ctx.editMessageText("ðŸ“– *ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒ*\n\n1. Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»ÑŒ AI\n2. ÐŸÐ¸ÑˆÐ¸Ñ‚Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹\n3. ÐŸÐ¾Ð»ÑƒÑ‡Ð°Ð¹Ñ‚Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹!", 
        { reply_markup: new InlineKeyboard().text("Â« ÐœÐµÐ½ÑŽ", "menu"), parse_mode: "Markdown" });
      break;
  }
});

bot.on("message:text", async (ctx) => {
  if (ctx.message.text.startsWith("/")) return;
  const userId = ctx.from.id;
  const model = userModels.get(userId) || "llama-3.1-8b-instant";
  const thinking = await ctx.reply("ðŸ¤” Ð”ÑƒÐ¼Ð°ÑŽ...");
  try {
    const answer = await askGroq(model, ctx.message.text);
    await ctx.api.deleteMessage(ctx.chat.id, thinking.message_id);
    await ctx.reply(answer, { reply_markup: new InlineKeyboard().text("ðŸ  ÐœÐµÐ½ÑŽ", "menu") });
  } catch (e) {
    await ctx.api.deleteMessage(ctx.chat.id, thinking.message_id);
    await ctx.reply(`âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: ${e.message}`);
  }
});

async function askGroq(model, prompt) {
  const key = process.env.GROQ_API_KEY;
  if (!key) throw new Error("GROQ_API_KEY Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½");
  const res = await fetch("https://api.groq.com/openai/v1/chat/completions", {
    method: "POST",
    headers: { "Content-Type": "application/json", "Authorization": `Bearer ${key}` },
    body: JSON.stringify({
      model: model,
      messages: [
        { role: "system", content: "Ð¢Ñ‹ helpful AI assistant. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼." },
        { role: "user", content: prompt }
      ],
      temperature: 0.7,
      max_tokens: 500
    })
  });
  if (!res.ok) throw new Error(`Groq API: ${res.status}`);
  const data = await res.json();
  return data.choices[0]?.message?.content || "ÐÐµÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð°";
}

bot.catch((err) => { console.error("Bot error:", err); });

module.exports = webhookCallback(bot, "std/http");
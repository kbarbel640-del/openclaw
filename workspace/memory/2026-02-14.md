# 2026-02-14

## OpenClaw Update
- Updated fork to latest upstream (320 commits merged)
- Push already done to `akeshr/openclaw` main
- On `main` branch, 32 commits ahead of upstream

## Image Gen Skill — Deep Research

### Google Gemini Skill Installed
- `npx skills add google-gemini/gemini-skills --skill gemini-api-dev --global --yes`
- Installed to: Antigravity, Claude Code, OpenClaw, GitHub Copilot, Replit
- Location: `~\.agents\skills\gemini-api-dev\SKILL.md`
- Contains current SDK patterns, model names, code examples

### Deep Dive into AutifyME's Image Studio
- Full analysis: `workspace/analysis/image-gen-deep-dive.md`
- 770-line tool wrapping Gemini 3 Pro Image via LangChain
- 12 structured spec types (extraction, fidelity, background, lighting, composition, scene, placement, material_treatment, enhancement, focus, custom_spec, output)
- Labeled images architecture: [source], [product], [style_ref] references
- Photography-expert system prompt for Gemini
- 40+ protocol files for domain knowledge (catalog, lifestyle, social)

### KEY RESEARCH FINDING: Plain Text > JSON for Gemini Image Prompts

Google's official docs and cookbook show that Nano Banana models use **plain text prompts**, NOT structured JSON:

**Google's approach:**
```python
response = client.models.generate_content(
    model="gemini-2.5-flash-image",
    contents=[text_prompt, PIL.Image.open('photo.jpg')],
    config=types.GenerateContentConfig(
        image_config=types.ImageConfig(aspect_ratio="1:1", image_size="2K")
    )
)
```

**Google's best practices for prompts:**
- Be hyper-specific in natural language ("ornate elven plate armor, etched with silver leaf patterns")
- Provide context and intent ("Create a logo for a high-end, minimalist skincare brand")
- Use step-by-step instructions for complex scenes
- Use "semantic negative prompts" (describe what you WANT, not "no X")
- Control camera with photographic language ("wide-angle shot", "macro shot", "low-angle perspective")
- Use chat mode for iterative editing (recommended by Google)
- Iterate and refine conversationally

**Google's product photography template:**
```
A high-resolution, studio-lit product photograph of a [product] on a [surface].
The lighting is a [setup] to [purpose]. The camera angle is a [angle] to showcase [feature].
Ultra-realistic, with sharp focus on [detail]. [Aspect ratio].
```

**Key differences from AutifyME's approach:**
1. AutifyME built structured JSON specs → fed as JSON prompt to Gemini
2. Google recommends plain text prompts with rich descriptive language
3. Chat mode is recommended for iterative editing (AutifyME used stateless calls)
4. PIL Images passed directly (no base64 encoding needed with new SDK)
5. Two models: `gemini-2.5-flash-image` (fast/cheap) and `gemini-3-pro-image-preview` (thinking, search, 4K)

### Implications for Our Skill Design

**Major redesign needed:**
- Tool should build a rich plain-text prompt, NOT pass JSON specs to Gemini
- The 12 spec types become a prompt-building framework, not API parameters
- Chat mode should be the primary editing path (maintains context between calls)
- Support both models with smart selection
- `google-genai` SDK handles image I/O natively (PIL objects)

### Models Available
| Model | Alias | Strengths | Input Images | Resolution |
|-------|-------|-----------|-------------|------------|
| `gemini-2.5-flash-image` | Nano Banana | Fast, cheap, default | Up to 3 (high fidelity) | 1K only |
| `gemini-3-pro-image-preview` | Nano Banana Pro | Thinking, search grounding, 4K | Up to 14 (6 high fidelity) | 1K, 2K, 4K |

### Next: Redesign the tool based on these findings
- Abhishek wants: research first, then design improvements
- Key insight: Abhishek was RIGHT that plain text works better with Gemini

### Design Brief Finalized & Approved
- Abhishek approved the image-gen skill design
- Two operations: `generate` (new image) and `edit` (modify existing via chat mode)
- 12 specs composed into plain text prompt by skill, NOT sent as JSON to Gemini
- Chat sessions stored as JSON files for iterative editing continuity
- `--file request.json` interface matching DB skill pattern
- Output: saves image to disk, returns path + metadata JSON
- Still TODO: fetch prompt guide, install packages, build the actual script

### Blockers
- ~~`GEMINI_API_KEY` not yet confirmed available~~ RESOLVED — `GOOGLE_API_KEY` in workspace root `.env`
- ~~`google-genai` and `Pillow` not yet installed~~ RESOLVED — both installed
- ~~Need to fetch prompt guide~~ RESOLVED — fetched via browser tool

## Image Gen Skill — COMPLETE ✅

### Built & Tested
- **Location:** `workspace/skills/image-gen/`
- **Script:** `scripts/image_gen.py` (~350 lines)
- **Commands:** generate, edit (chat sessions), list_sessions
- **Models:** `gemini-2.5-flash-image` (default) + `gemini-3-pro-image-preview` (quality)
- **Interface:** `--file request.json` (same as db_tool.py)
- **All specs composed into plain text prompts** (not JSON to Gemini)
- **Google Search grounding** supported for pro model
- **10 aspect ratios:** 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9, 21:9

### Regression: 23/23 PASS
- 6 unit tests (key loading, prompt builder, paths, aspect ratios)
- 17 integration tests (live API — text-to-image, specs, formats, aspect ratios, lifestyle, social)
- All formats tested: PNG, JPEG, WEBP
- All generating correctly with proper dimensions

### Bug Fixed During Testing
- `part.as_image()` returns `google.genai.types.Image`, NOT `PIL.Image`
- Had to convert via `Image.open(io.BytesIO(part.inline_data.data))` for format control

### Key Architecture Decisions
- **Single .env at workspace root** — all skills share it, never skill-specific .env
- **GOOGLE_API_KEY** (not GEMINI_API_KEY) as primary env var name
- **Browser tool works** for fetching docs when web_fetch fails (redirects)
- Abhishek gave blanket authority to use browser for web navigation

#!/usr/bin/env python3
"""
Threads å¹³å°æ¢ç´¢å™¨
å­¸ç¿’ Threads å¹³å°ç‰¹æ€§ï¼Œåˆ†ææˆåŠŸè²¼æ–‡æ¨¡å¼
"""

import json
import time
from datetime import datetime
from pathlib import Path

class ThreadsExplorer:
    def __init__(self, data_dir="data/threads"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # å­¸ç¿’è³‡æ–™åº«
        self.learning_db = self.data_dir / "learning.json"
        self.post_patterns_db = self.data_dir / "patterns.json"
        
        # åˆå§‹åŒ–è³‡æ–™åº«
        self.init_databases()
    
    def init_databases(self):
        """åˆå§‹åŒ–å­¸ç¿’è³‡æ–™åº«"""
        if not self.learning_db.exists():
            base_learning = {
                "platform_characteristics": {
                    "emoji_usage": "ç²¾ç°¡ã€æœ‰ç¯€å¥ã€è¦–è¦ºå¼•å°",
                    "paragraph_structure": "çŸ­æ®µè½ã€ç©ºè¡Œåˆ†éš”",
                    "content_preferences": ["å·¥å…·æ¨è–¦", "è¶¨å‹¢åˆ†æ", "ç¶“é©—åˆ†äº«"],
                    "interaction_patterns": ["æå•çµå°¾", "é‚€è«‹è¨è«–", "åƒ¹å€¼åˆ†äº«"],
                    "no_multi_tags": True
                },
                "successful_patterns": [],
                "failed_patterns": [],
                "engagement_metrics": {},
                "last_updated": datetime.now().isoformat()
            }
            self.save_json(self.learning_db, base_learning)
        
        if not self.post_patterns_db.exists():
            base_patterns = {
                "tool_recommendation": {
                    "structure": ["å•é¡Œå¼•å…¥", "å·¥å…·åˆ—è¡¨", "è¡Œå‹•å»ºè­°"],
                    "emoji_pattern": "ğŸ› ï¸ğŸ“‹ğŸš€",
                    "example": "æƒ³å­¸ AI é–‹ç™¼ï¼Ÿé€™ 5 å€‹å·¥å…·è®“ä½ å°‘èµ°åŠå¹´å½è·¯...",
                    "success_rate": 0,
                    "avg_engagement": 0
                },
                "trend_analysis": {
                    "structure": ["ç¾è±¡æè¿°", "æ·±åº¦åˆ†æ", "æ©Ÿæœƒé»"],
                    "emoji_pattern": "ğŸ“ˆğŸ”ğŸ’¡", 
                    "example": "Google/å¾®è»ŸåŒæ™‚å‡ºæ‰‹ï¼ŒAI åŸºç¤è¨­æ–½å¤§å‡ç´šæ„å‘³è‘—ä»€éº¼ï¼Ÿ",
                    "success_rate": 0,
                    "avg_engagement": 0
                },
                "story_sharing": {
                    "structure": ["æ•…äº‹èƒŒæ™¯", "é—œéµåšæ³•", "å¿ƒå¾—å•Ÿç™¼"],
                    "emoji_pattern": "ğŸ“–ğŸ¯ğŸ¤",
                    "example": "æˆ‘çš„ AI è‡ªå‹•åŒ–ç³»çµ±æ»¿æœˆå ±å‘Šï¼šæ¯é€±çœä¸‹ 20 å°æ™‚...",
                    "success_rate": 0,
                    "avg_engagement": 0
                }
            }
            self.save_json(self.post_patterns_db, base_patterns)
    
    def save_json(self, path, data):
        """å„²å­˜ JSON è³‡æ–™"""
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def load_json(self, path):
        """è¼‰å…¥ JSON è³‡æ–™"""
        if path.exists():
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def analyze_post(self, post_data):
        """åˆ†æè²¼æ–‡ç‰¹å¾µ"""
        analysis = {
            "length": len(post_data.get("content", "")),
            "paragraph_count": post_data.get("content", "").count('\n\n') + 1,
            "emoji_count": self.count_emojis(post_data.get("content", "")),
            "has_question": "?" in post_data.get("content", ""),
            "has_call_to_action": any(word in post_data.get("content", "").lower() 
                                    for word in ["ä½ è¦ºå¾—", "ä½ çš„çœ‹æ³•", "åˆ†äº«ä½ çš„", "ç•™è¨€å‘Šè¨´"]),
            "engagement_ratio": self.calculate_engagement_ratio(post_data),
            "pattern_match": self.match_pattern(post_data.get("content", ""))
        }
        return analysis
    
    def count_emojis(self, text):
        """è¨ˆç®— emoji æ•¸é‡ï¼ˆç°¡åŒ–ç‰ˆï¼‰"""
        # ç°¡å–®çš„ emoji æª¢æ¸¬
        emoji_ranges = [
            (0x1F600, 0x1F64F),  # è¡¨æƒ…ç¬¦è™Ÿ
            (0x1F300, 0x1F5FF),  # å…¶ä»–ç¬¦è™Ÿ
            (0x1F680, 0x1F6FF),  # äº¤é€šå’Œåœ°åœ–ç¬¦è™Ÿ
            (0x2600, 0x26FF),    # é›œé …ç¬¦è™Ÿ
            (0x2700, 0x27BF),    # è£é£¾ç¬¦è™Ÿ
            (0xFE00, 0xFE0F),    # è®Šé«”é¸æ“‡å™¨
            (0x1F900, 0x1F9FF),  # è£œå……ç¬¦è™Ÿ
        ]
        
        count = 0
        for char in text:
            code = ord(char)
            for start, end in emoji_ranges:
                if start <= code <= end:
                    count += 1
                    break
        return count
    
    def calculate_engagement_ratio(self, post_data):
        """è¨ˆç®—äº’å‹•ç‡ï¼ˆç°¡åŒ–ç‰ˆï¼‰"""
        likes = post_data.get("likes", 0)
        replies = post_data.get("replies", 0)
        reposts = post_data.get("reposts", 0)
        shares = post_data.get("shares", 0)
        
        total_engagement = likes + replies * 3 + reposts * 5 + shares * 10
        return total_engagement
    
    def match_pattern(self, content):
        """åŒ¹é…è²¼æ–‡æ¨¡å¼"""
        content_lower = content.lower()
        patterns = self.load_json(self.post_patterns_db)
        
        matched = []
        for pattern_name, pattern_info in patterns.items():
            # ç°¡å–®çš„é—œéµå­—åŒ¹é…
            keywords = {
                "tool_recommendation": ["å·¥å…·", "æ¨è–¦", "æ¸…å–®", "top", "æœ€å¥½ç”¨"],
                "trend_analysis": ["è¶¨å‹¢", "åˆ†æ", "å¸‚å ´", "æœªä¾†", "æ©Ÿæœƒ"],
                "story_sharing": ["ç¶“é©—", "æ•…äº‹", "åˆ†äº«", "å¿ƒå¾—", "æ•™è¨“"]
            }
            
            if pattern_name in keywords:
                for keyword in keywords[pattern_name]:
                    if keyword in content_lower:
                        matched.append(pattern_name)
                        break
        
        return matched if matched else ["unknown"]
    
    def update_learning(self, post_data, analysis):
        """æ›´æ–°å­¸ç¿’è³‡æ–™åº«"""
        learning = self.load_json(self.learning_db)
        patterns = self.load_json(self.post_patterns_db)
        
        # è¨˜éŒ„æˆåŠŸæ¨¡å¼
        if analysis["engagement_ratio"] > 100:  # å‡è¨­é–€æª»
            learning["successful_patterns"].append({
                "timestamp": datetime.now().isoformat(),
                "content_preview": post_data.get("content", "")[:100],
                "analysis": analysis,
                "engagement": analysis["engagement_ratio"]
            })
            
            # æ›´æ–°æ¨¡å¼æˆåŠŸç‡
            for pattern in analysis["pattern_match"]:
                if pattern in patterns and pattern != "unknown":
                    patterns[pattern]["success_rate"] += 1
                    patterns[pattern]["avg_engagement"] = (
                        (patterns[pattern]["avg_engagement"] * (patterns[pattern]["success_rate"] - 1) +
                         analysis["engagement_ratio"]) / patterns[pattern]["success_rate"]
                    )
        
        # ä¿æŒè³‡æ–™åº«å¤§å°
        if len(learning["successful_patterns"]) > 100:
            learning["successful_patterns"] = learning["successful_patterns"][-100:]
        
        learning["last_updated"] = datetime.now().isoformat()
        
        self.save_json(self.learning_db, learning)
        self.save_json(self.post_patterns_db, patterns)
    
    def generate_insights_report(self):
        """ç”Ÿæˆå­¸ç¿’æ´å¯Ÿå ±å‘Š"""
        learning = self.load_json(self.learning_db)
        patterns = self.load_json(self.post_patterns_db)
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "total_posts_analyzed": len(learning.get("successful_patterns", [])) + 
                                   len(learning.get("failed_patterns", [])),
            "platform_characteristics": learning.get("platform_characteristics", {}),
            "pattern_performance": {},
            "recommendations": []
        }
        
        # åˆ†ææ¨¡å¼è¡¨ç¾
        for pattern_name, pattern_info in patterns.items():
            if pattern_info["success_rate"] > 0:
                report["pattern_performance"][pattern_name] = {
                    "success_rate": pattern_info["success_rate"],
                    "avg_engagement": pattern_info["avg_engagement"],
                    "recommended_emoji": pattern_info["emoji_pattern"]
                }
        
        # ç”Ÿæˆå»ºè­°
        if report["pattern_performance"]:
            best_pattern = max(report["pattern_performance"].items(), 
                             key=lambda x: x[1]["avg_engagement"])
            report["recommendations"].append(
                f"æœ€æœ‰æ•ˆçš„æ¨¡å¼ï¼š{best_pattern[0]} (å¹³å‡äº’å‹•ï¼š{best_pattern[1]['avg_engagement']:.1f})"
            )
            report["recommendations"].append(
                f"å»ºè­° emoji æ¨¡å¼ï¼š{best_pattern[1]['recommended_emoji']}"
            )
        
        # å¹³å°ç‰¹æ€§å»ºè­°
        if learning.get("platform_characteristics", {}).get("no_multi_tags"):
            report["recommendations"].append(
                "Threads æ²’æœ‰ multi tags åŠŸèƒ½ï¼Œä½¿ç”¨å–®ä¸€ç²¾æº–æ¨™ç±¤å³å¯"
            )
        
        return report
    
    def explore_from_snapshot(self, snapshot_data):
        """å¾ç€è¦½å™¨ snapshot æ¢ç´¢è²¼æ–‡"""
        # é€™è£¡å¯ä»¥æ•´åˆ browser å·¥å…·çš„ snapshot æ•¸æ“š
        # æš«æ™‚ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š
        mock_posts = [
            {
                "content": "ğŸ› ï¸ æƒ³é–‹å§‹ AI é–‹ç™¼ä½†ä¸çŸ¥é“å¾å“ªå…¥æ‰‹ï¼Ÿ\n\né€™ 5 å€‹å·¥å…·è®“æˆ‘å°‘èµ°åŠå¹´å½è·¯...",
                "likes": 28000,
                "replies": 54,
                "reposts": 4125,
                "shares": 10000
            },
            {
                "content": "ğŸ“ˆ Google å’Œå¾®è»ŸåŒæ™‚å‡ºæ‰‹äº†ï¼\n\né€™é€±å…©ä»¶å¤§äº‹ï¼š\n1. Google LiteRT - è·¨å¹³å° AI åŠ é€Ÿæ¶æ§‹\n2. å¾®è»Ÿ Copilot - Windows 11 ç³»çµ±ç´šæ•´åˆ",
                "likes": 9275,
                "replies": 85,
                "reposts": 1055,
                "shares": 9575
            }
        ]
        
        insights = []
        for post in mock_posts:
            analysis = self.analyze_post(post)
            self.update_learning(post, analysis)
            insights.append({
                "content_preview": post["content"][:50] + "...",
                "analysis": analysis
            })
        
        return insights

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸ§ª Threads å¹³å°æ¢ç´¢å™¨å•Ÿå‹•...")
    
    explorer = ThreadsExplorer()
    
    # æ¨¡æ“¬æ¢ç´¢
    print("\nğŸ” æ¨¡æ“¬æ¢ç´¢ Threads è²¼æ–‡...")
    insights = explorer.explore_from_snapshot({})
    
    for i, insight in enumerate(insights, 1):
        print(f"\nè²¼æ–‡ {i}: {insight['content_preview']}")
        print(f"  é•·åº¦: {insight['analysis']['length']} å­—å…ƒ")
        print(f"  emoji æ•¸é‡: {insight['analysis']['emoji_count']}")
        print(f"  æ®µè½æ•¸: {insight['analysis']['paragraph_count']}")
        print(f"  åŒ¹é…æ¨¡å¼: {', '.join(insight['analysis']['pattern_match'])}")
        print(f"  äº’å‹•åˆ†æ•¸: {insight['analysis']['engagement_ratio']:.1f}")
    
    # ç”Ÿæˆå ±å‘Š
    print("\nğŸ“Š å­¸ç¿’æ´å¯Ÿå ±å‘Š:")
    report = explorer.generate_insights_report()
    print(f"åˆ†æè²¼æ–‡æ•¸: {report['total_posts_analyzed']}")
    
    if report['pattern_performance']:
        print("\næ¨¡å¼è¡¨ç¾:")
        for pattern, perf in report['pattern_performance'].items():
            print(f"  {pattern}: æˆåŠŸç‡ {perf['success_rate']}, å¹³å‡äº’å‹• {perf['avg_engagement']:.1f}")
    
    if report['recommendations']:
        print("\nå»ºè­°:")
        for rec in report['recommendations']:
            print(f"  â€¢ {rec}")
    
    # å„²å­˜å ±å‘Š
    report_path = explorer.data_dir / f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    explorer.save_json(report_path, report)
    print(f"\nâœ… å ±å‘Šå·²å„²å­˜è‡³: {report_path}")

if __name__ == "__main__":
    main()